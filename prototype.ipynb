{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rising-helena",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romantic-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mehrazin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mehrazin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from prepross import *\n",
    "import numpy as np\n",
    "import os\n",
    "import dataloader\n",
    "from dataloader import Vocab\n",
    "pd.options.display.max_rows = 100\n",
    "from embedding import Doc2VecEmbedding\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expensive-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parse():\n",
    "    def __init__(self):\n",
    "        self.test_mode = True\n",
    "        self.load_vocab = True\n",
    "        self.exp_id = 0\n",
    "        self.load_model = False\n",
    "        self.prepare_data = True\n",
    "        self.save_every = 10\n",
    "        self.dump_loss = True\n",
    "        self.num_epochs = 10\n",
    "        self.batch_size = 4\n",
    "arg = Parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preliminary-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relevant-entrance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mehrazin/Documents/DAV_project/Repository/Music-Recommendation/Dumped/10'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.exp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "injured-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mehrazin/Documents/DAV_project/Repository/Music-Recommendation/Dataset/Test/1k-item/Datasets'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.Dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "military-classification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "romance-composition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = Data_handler(config, pass_col = ['lyrics'])\n",
    "# df.data = df.get_masked_data(users = df.users[:3], fracs = [0.1,0.2,0.1])\n",
    "# df.data = create_session(df.data, config)\n",
    "# df.data = clean_data(df.data, config)\n",
    "# df.data = cut_sessions(df.data, config)\n",
    "# config.clean_mode = ['rm_small_sub_session']\n",
    "# df.data = clean_data(df.data, config)\n",
    "# df.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-culture",
   "metadata": {},
   "source": [
    "# Model Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faced-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataloader import Music_data, create_data_loader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import Model\n",
    "import random\n",
    "from Model import create_embeding, Seq2Seq, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proof-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\"\"\"Set seed\"\"\"\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "soviet-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_epochs = 1000\n",
    "config.batch_size = 50\n",
    "config.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "separated-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, dim, _ = Model.create_embeding(config)\n",
    "train_iterator = create_data_loader(config, 'train', shuffle = True)\n",
    "test_iterator = create_data_loader(config, 'test', shuffle = True)\n",
    "valid_iterator = create_data_loader(config, 'valid', shuffle = True)\n",
    "itr = iter(train_iterator)\n",
    "# df = Music_data(config, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "transparent-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(config).to(config.device)\n",
    "dec = Decoder(config).to(config.device)\n",
    "model = Seq2Seq(config, enc, dec).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "explicit-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "pad_idx = config.pad_index\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acquired-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "optional-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit a single batch\n",
    "batch = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aggregate-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u, i, o = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "considered-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.091909408569336\n",
      "0.9341719746589661\n",
      "0.10340725630521774\n",
      "0.018536578863859177\n",
      "0.018866803497076035\n",
      "0.006097143515944481\n",
      "0.0028595509938895702\n",
      "0.0020739464089274406\n",
      "0.0016656732186675072\n",
      "0.0013940101489424706\n",
      "0.0011945615988224745\n",
      "0.001040349598042667\n",
      "0.0009172148420475423\n",
      "0.0008164584869518876\n",
      "0.0007324117468670011\n",
      "0.0006614225567318499\n",
      "0.0006009263452142477\n",
      "0.0005488931783474982\n",
      "0.0005038205999881029\n",
      "0.000464396842289716\n",
      "0.0004296386323403567\n",
      "0.0003988281241618097\n",
      "0.0003713247715495527\n",
      "0.00034668773878365755\n",
      "0.0003245103289373219\n",
      "0.00030449480982497334\n",
      "0.00028639769880101085\n",
      "0.0002699614269658923\n",
      "0.00025499050389043987\n",
      "0.00024129181110765785\n",
      "0.00022871782130096108\n",
      "0.00021714762260671705\n",
      "0.00020646335906349123\n",
      "0.0001965644332813099\n",
      "0.00018737632490228862\n",
      "0.00017883526743389666\n",
      "0.00017088293679989874\n",
      "0.00016344395407941192\n",
      "0.0001565015991218388\n",
      "0.00015000304847490042\n",
      "0.00014390406431630254\n",
      "0.00013815874990541488\n",
      "0.00013278290862217546\n",
      "0.00012771486944984645\n",
      "0.00012294731277506799\n",
      "0.00011843212269013748\n",
      "0.00011416767665650696\n",
      "0.00011013401672244072\n",
      "0.0001063252566382289\n",
      "0.0001027030375553295\n",
      "Performance: 409.31586579 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "for epoch in range(config.num_epochs):\n",
    "#     for batch_idx, batch in enumerate(train_iterator):\n",
    "    users, source, target = batch\n",
    "    users = users.to(config.device)\n",
    "    source = (source[0].to(config.device), source[1].to(config.device))\n",
    "    target = (target[0].to(config.device), target[1].to(config.device))\n",
    "    output = model(config, users, source, target)\n",
    "\n",
    "    output = output[1:].reshape(-1, output.shape[2])\n",
    "    target = target[0][1:].reshape(-1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Back prop\n",
    "    loss.backward()\n",
    "    if epoch%20 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "    # within a healthy range\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "    # Gradient descent step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Plot to tensorboard\n",
    "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "    step += 1\n",
    "toc = time.perf_counter()\n",
    "print(f'Performance: {toc - tic:0.8f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
